{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of training LLMs, we have 3 approaches: Pre-training, Fine-tuning, LoRa and QLoRA\n",
    "\n",
    "1. Pre-training:\n",
    "- Imagine you have a massive text dataset\n",
    "- identify the model architecture\n",
    "- Tokenizer will help in encoding and decoding based on the tasks\n",
    "- Dataset is preprocessed using the tokenizer's vocab\n",
    "\n",
    "After these steps you will have a suitable data in a required format for training the model. This step will involve mapping tokens to corresponding IDs, incorporating any special tokens/attention mask. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An attention mask is a tool used in natural language processing (NLP) and deep learning models to help the model focus on the most important parts of the input data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pre-training stage the model learns to predict the next word in the sentence(text generation - causal language modeling) / fill-in missing words(masked language model MLM). The model understands the basic understanding of grammar, language patterns and semantic relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After pre-training, the model is able to capture general language but it lacks  specific knowledge about a particular domain/task. That is the reason we fine-tune the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Finetuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuning helps us to specialize the LLM's capabilities and optimize its performance on a narrower and task specific dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the instruction-tuned model, you need a dataset with instructions and response. The fine-tuned dataset is much smaller than the pre-trained dataset. In fine-tuning we try to minimize the task specific loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient-based optimizing algorithms are a type of optimization technique used in machine learning and deep learning to minimize the loss function or error between the model's predictions and the actual output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters of the pre-trained model are adjusted using gradient-based optimization algorithms such as adam, stochastic gradient descent(SGD) etc. These use back propagation which allows the model to learn from its mistakes and update its parameter weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also improve the mdoel using parameters such as learning rate, regularization methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization models in fine-tuning are techniques used to prevent overfitting and improve the generalization of pre-trained models when fine-tuning them on a new task or dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. LoRA [Low Rank Adaptation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning is expensive. LoRa can reduce the number of parameters to be trained by 10,000 times and usage of ,memeory requirements by 3 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a training method designed to expedite the training process of LLMs.\n",
    "\n",
    "There are 3 important things related to LoRA:\n",
    "1. Presevation of Pre-trained weights : LoRA helps models retain its existing knowledge while adopting to new data\n",
    "\n",
    "2. Portability of trained weights: The rank decomposition matrices which are sued in LoRA have significatnly fewer parameters and this particular characteristic allows trained parameters weights to be transported to other context which make them highyl portable.\n",
    "\n",
    "3. Integration ith Attention Layers\n",
    "\n",
    "4. Improved Memory efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LoRA Hyperparameters:\n",
    "lora_r: 32 - LoRA rank - it determines the number of rank decomposition matrices - rank decomposition is applied to weight matrices to reduce memory consumption and computation requirements. By rule of thumb, r = 8 is recommended. Higher Rank is recommenbed for a more complex dataset and it needs high compute. \n",
    "\n",
    "lora_alpha: 16 - LoRA alpha is a scaling factor which determines the extend the rate to which the model adopts to the training data. Lower value gives more weight to original data and maintains the model's existing knowledge to a greater extent.\n",
    "\n",
    "lora_dropout: 0.05\n",
    "lora_target_linear: true\n",
    "lora_fan_in_fan_out:\n",
    "\n",
    "lora_target_modules: - Here you can determine which specific weights and matrices needs to be trained. the most common ones are query vectors and value vectors(q_proj and v_proj). The names vary based on the model which you can find using model.state_dict().keys()   \n",
    "  - gate_proj\n",
    "  - down_proj\n",
    "  - up_proj\n",
    "  - q_proj\n",
    "  - v_proj\n",
    "  - k_proj - key vectors\n",
    "  - o_proj - output of attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lm_head - output layer of language modelling repsonsible for prediction or scores for next token based on learned representation of preceding layer. If your data has a custom syntax.\n",
    "\n",
    "- embed_tokens - represent the parameters of embedding layers usually placed at the beginning of the mdoel which maps input tokens to vector representations. \n",
    "\n",
    "- norm - normalization layers used to improve stability and convergence of deep neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. QLoRA [Quantized LoRA]\n",
    "- Uses a library called BitsAndBytes(bnb) and achieves a near loss less quantization. this results in massive reducation in memory requirements and help in fine-tuning models such as LLAMA \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach, we include back propagation of gradients through a froze 4 bit quantized into LoRA. It uses a new data type called nf4(4 bit normal float). nf$ optimally handles normally distributed weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LoRA (Low-Rank Adaptation) and QLoRA (Quantized Low-Rank Adaptation) are both techniques for fine-tuning pre-trained language models, but they differ in how they adapt the model's weights:\n",
    "\n",
    "LoRA:\n",
    "- Fine-tunes the model's weights using low-rank decomposition matrices (pairs of matrices)\n",
    "- Updates the entire weight matrix, but with a low-rank approximation\n",
    "- Requires floating-point numbers to represent the weights\n",
    "\n",
    "QLoRA:\n",
    "- Fine-tunes the model's weights using quantized low-rank decomposition matrices (pairs of matrices with reduced precision)\n",
    "- Updates the entire weight matrix, but with a low-rank approximation and reduced precision (e.g., 8-bit integers)\n",
    "- Requires less memory and computation than LoRA, making it more efficient\n",
    "\n",
    "\n",
    "In simple terms:\n",
    "LoRA is like refining a detailed picture, while QLoRA is like refining a simplified sketch.\n",
    "LoRA uses more precise weights, while QLoRA uses approximate weights with reduced precision.\n",
    "QLoRA is a more efficient and lightweight version of LoRA, making it suitable for deployment on devices with limited resources, like mobile devices or embedded systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some additional hyperparameters:\n",
    "- num_epochs : Hyperparameter which controls the number of iterations of forward and back propagation. Each epoch involves processing the entire dataset once.\n",
    "\n",
    "- Batch size : Number of training samples processed before in samples\n",
    "\n",
    "- Stochastic Gradient Descent helps in finding best parameters of the model. Usually stochastic gradient descent, batch gradient descent, mini batch gradient descent are methods used to train models commonly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Learning rate : Hyperparameter which controls the step size of the gradient descent algorithm. If the learning rate is too long, it takes too long to get to the optimal minima and if it is too large, it doesn;t fine-tune properly. So it is important to find optimal learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Size is the number of samples processed before the model is updated but epcohs is the numebr of iterations of dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example if the dataset has 200 rows and a batch size of 5 with epoch of 1000, then the weights are updated after each batch of 5 so in each epoch, the model weight is updated 40 times."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
